{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "advisory-webster",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install https://github.com/p-koo/tfomics/tarball/master"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "behind-particle",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "welcome-monaco",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.models import Model\n",
    "\n",
    "import numpy as np\n",
    "import requests as rq\n",
    "import os, io, h5py\n",
    "import pickle as pk\n",
    "\n",
    "from tfomics import moana"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "orange-military",
   "metadata": {},
   "source": [
    "# Retrieve Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "otherwise-eleven",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = rq.get('https://www.dropbox.com/s/c3umbo5y13sqcfp/synthetic_dataset.h5?raw=true')\n",
    "data.raise_for_status()\n",
    "\n",
    "with h5py.File(io.BytesIO(data.content), 'r') as dataset:\n",
    "    x_train = np.array(dataset['X_train']).astype(np.float32).transpose([0, 2, 1])\n",
    "    y_train = np.array(dataset['Y_train']).astype(np.float32)\n",
    "    x_valid = np.array(dataset['X_valid']).astype(np.float32).transpose([0, 2, 1])\n",
    "    y_valid = np.array(dataset['Y_valid']).astype(np.int32)\n",
    "    x_test = np.array(dataset['X_test']).astype(np.float32).transpose([0, 2, 1])\n",
    "    y_test = np.array(dataset['Y_test']).astype(np.int32)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "threaded-science",
   "metadata": {},
   "source": [
    "# Connect to Drive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "analyzed-contrast",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive', force_remount=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "running-digest",
   "metadata": {},
   "source": [
    "# Define Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "impressive-combat",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model-001\n",
      "model-016\n",
      "model-032\n",
      "model-064\n",
      "model-128\n",
      "model-256\n"
     ]
    }
   ],
   "source": [
    "category = \"filters\"\n",
    "variants = [1, 16, 32, 64, 128, 256]\n",
    "\n",
    "models = []\n",
    "\n",
    "places = len(str(max(variants)))\n",
    "\n",
    "for i in range(len(variants)):\n",
    "    # Input\n",
    "    inputs = layers.Input(shape=(200, 4))\n",
    "\n",
    "    # Convolutional Block\n",
    "    nn = layers.Conv1D(filters=variants[i], kernel_size=19, use_bias=False, padding='same')(inputs)\n",
    "    nn = layers.Activation('relu', name='conv_activation')(nn)\n",
    "    nn = layers.MaxPool1D(pool_size=25)(nn)\n",
    "    nn = layers.Dropout(0.1)(nn)\n",
    "\n",
    "    # Positional Encoding\n",
    "    positions = tf.range(nn.shape[1])\n",
    "    context = layers.Embedding(input_dim=nn.shape[1], output_dim=nn.shape[2])(positions)\n",
    "    nn = tf.add(nn, context)\n",
    "\n",
    "    # Multi-Head Attention\n",
    "    nn, weights = layers.MultiHeadAttention(num_heads=16, key_dim=64)(nn, nn, return_attention_scores=True)\n",
    "    nn = layers.Dropout(0.1)(nn)\n",
    "    nn = layers.LayerNormalization()(nn)\n",
    "\n",
    "    nn = layers.Flatten()(nn)\n",
    "\n",
    "    # Feed Forward\n",
    "    nn = layers.Dense(512, use_bias=False)(nn)\n",
    "    nn = layers.BatchNormalization()(nn)\n",
    "    nn = layers.Activation('relu')(nn)\n",
    "    nn = layers.Dropout(0.5)(nn)\n",
    "\n",
    "    # Output\n",
    "    outputs = layers.Dense(12, activation='sigmoid')(nn)\n",
    "\n",
    "    # Compile model\n",
    "    model = Model(inputs=inputs, outputs=outputs, name=f\"model-{str(variants[i]).zfill(places)}\")\n",
    "    print(model.name)\n",
    "\n",
    "    auroc = tf.keras.metrics.AUC(curve='ROC', name='auroc')\n",
    "    aupr = tf.keras.metrics.AUC(curve='PR', name='aupr')\n",
    "    model.compile(tf.keras.optimizers.Adam(0.0005), loss='binary_crossentropy', metrics=[auroc, aupr])\n",
    "    \n",
    "    models.append(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "functioning-antarctica",
   "metadata": {},
   "source": [
    "# Train Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "amino-plate",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(models)):\n",
    "    lr_decay = tf.keras.callbacks.ReduceLROnPlateau(monitor='val_aupr', factor=0.2, patient=5, verbose=1, min_lr=1e-7, mode='max')\n",
    "    checkpoint = tf.keras.callbacks.ModelCheckpoint(filepath=f'/content/drive/MyDrive/Colab Notebooks/ConvAttData/models/{category}/{models[i].name}.h5', monitor='val_aupr')\n",
    "\n",
    "    print('\\n' + models[i].name)\n",
    "    models[i].fit(x_train, y_train, epochs=75, validation_data=(x_valid, y_valid), callbacks=[lr_decay, checkpoint], verbose=2, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "centered-musician",
   "metadata": {},
   "source": [
    "# Extract PPMs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "fuzzy-offense",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'models' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-12-4d6955b64973>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      6\u001b[0m     \u001b[0mm\u001b[0m \u001b[1;33m//=\u001b[0m \u001b[1;36m10\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mplaces\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 8\u001b[1;33m \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodels\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      9\u001b[0m     \u001b[1;32mbreak\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m     \u001b[0mindex\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mtype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mj\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mj\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mmodels\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mActivation\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'models' is not defined"
     ]
    }
   ],
   "source": [
    "for i in range(len(models)):\n",
    "    index = [type(j) for j in models[i].layers].index(tf.keras.layers.Activation)\n",
    "    \n",
    "    ppms = moana.filter_activations(x_test, models[i], layer=index, window=20, threshold=0.5)\n",
    "    ppms = moana.clip_filters(ppms, threshold=0.5, pad=3)\n",
    "    \n",
    "    if not os.path.exists(f'/content/drive/MyDrive/Colab Notebooks/ConvAttData/motifs/{category}'):\n",
    "        os.makedirs(f'/content/drive/MyDrive/Colab Notebooks/ConvAttData/motifs/{category}')\n",
    "\n",
    "    moana.meme_generate(ppms, output_file=f'/content/drive/MyDrive/Colab Notebooks/ConvAttData/motifs/{category}/{models[i].name}.txt', prefix='filter')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
