{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "advisory-webster",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install https://github.com/p-koo/tfomics/tarball/master"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "behind-particle",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "welcome-monaco",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.models import Model\n",
    "\n",
    "import numpy as np\n",
    "import requests as rq\n",
    "import io, h5py\n",
    "import pickle as pk\n",
    "\n",
    "from tfomics import moana"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "orange-military",
   "metadata": {},
   "source": [
    "# Retrieve Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "otherwise-eleven",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = rq.get('https://www.dropbox.com/s/c3umbo5y13sqcfp/synthetic_dataset.h5?raw=true')\n",
    "data.raise_for_status()\n",
    "\n",
    "with h5py.File(io.BytesIO(data.content), 'r') as dataset:\n",
    "    x_train = np.array(dataset['X_train']).astype(np.float32).transpose([0, 2, 1])\n",
    "    y_train = np.array(dataset['Y_train']).astype(np.float32)\n",
    "    x_valid = np.array(dataset['X_valid']).astype(np.float32).transpose([0, 2, 1])\n",
    "    y_valid = np.array(dataset['Y_valid']).astype(np.int32)\n",
    "    x_test = np.array(dataset['X_test']).astype(np.float32).transpose([0, 2, 1])\n",
    "    y_test = np.array(dataset['Y_test']).astype(np.int32)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "threaded-science",
   "metadata": {},
   "source": [
    "# Connect to Drive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "analyzed-contrast",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive', force_remount=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "running-digest",
   "metadata": {},
   "source": [
    "# Define Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "impressive-combat",
   "metadata": {},
   "outputs": [],
   "source": [
    "category = \"pools\"\n",
    "variants = [1, 5, 15, 25, 50, 100]\n",
    "\n",
    "models = []\n",
    "\n",
    "for i in range(len(variants)):\n",
    "    # Input\n",
    "    inputs = layers.Input(shape=(200, 4))\n",
    "\n",
    "    # Convolutional Block\n",
    "    nn = layers.Conv1D(filters=32, kernel_size=19, use_bias=False, padding='same')(inputs)\n",
    "    nn = layers.Activation('relu', name='conv_activation')(nn)\n",
    "    nn = layers.MaxPool1D(pool_size=variants[i])(nn)\n",
    "    nn = layers.Dropout(0.1)(nn)\n",
    "\n",
    "    # Positional Encoding\n",
    "    positions = tf.range(nn.shape[1])\n",
    "    context = layers.Embedding(input_dim=positions.shape[0], output_dim=nn.shape[2])(positions)\n",
    "    nn = tf.add(nn, context)\n",
    "\n",
    "    # Multi-Head Attention\n",
    "    nn, weights = layers.MultiHeadAttention(num_heads=16, key_dim=64)(nn, nn, return_attention_scores=True)\n",
    "    nn = layers.Dropout(0.1)(nn)\n",
    "    nn = layers.LayerNormalization()(nn)\n",
    "\n",
    "    nn = layers.Flatten()(nn)\n",
    "\n",
    "    # Feed Forward\n",
    "    nn = layers.Dense(512, use_bias=False)(nn)\n",
    "    nn = layers.BatchNormalization()(nn)\n",
    "    nn = layers.Activation('relu')(nn)\n",
    "    nn = layers.Dropout(0.5)(nn)\n",
    "\n",
    "    # Output\n",
    "    outputs = layers.Dense(12, activation='sigmoid')(nn)\n",
    "\n",
    "    # Compile model\n",
    "    model = Model(inputs=inputs, outputs=outputs, name=f\"model-{variants[i]}\")\n",
    "\n",
    "    auroc = tf.keras.metrics.AUC(curve='ROC', name='auroc')\n",
    "    aupr = tf.keras.metrics.AUC(curve='PR', name='aupr')\n",
    "    model.compile(tf.keras.optimizers.Adam(0.0005), loss='binary_crossentropy', metrics=[auroc, aupr])\n",
    "    \n",
    "    models.append(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "functioning-antarctica",
   "metadata": {},
   "source": [
    "# Train Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "amino-plate",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(models)):\n",
    "    lr_decay = tf.keras.callbacks.ReduceLROnPlateau(monitor='val_aupr', factor=0.2, patient=5, verbose=1, min_lr=1e-7, mode='max')\n",
    "    checkpoint = tf.keras.callbacks.ModelCheckpoint(filepath=f'/content/drive/MyDrive/Colab Notebooks/ConvAttData/models/{category}/{models[i].name}.h5', monitor='val_aupr')\n",
    "\n",
    "    models[i].fit(x_train, y_train, epochs=75, validation_data=(x_valid, y_valid), callbacks=[lr_decay, checkpoint], verbose=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "centered-musician",
   "metadata": {},
   "source": [
    "# Extract PPMs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fuzzy-offense",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(models)):\n",
    "    index = [type(j) for j in models[i].layers].index(tf.keras.layers.Activation)\n",
    "    \n",
    "    ppms = moana.filter_activations(x_test, models[i], layer=index, window=20, threshold=0.5)\n",
    "    ppms = moana.clip_filters(ppms, threshold=0.5, pad=3)\n",
    "    \n",
    "    moana.meme_generate(ppms, output_file=f'/content/drive/MyDrive/Colab Notebooks/ConvAttData/motifs/{category}/{models[i].name}.meme', prefix='filter')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
