{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "advisory-webster",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting https://github.com/p-koo/tfomics/tarball/master\n",
      "  Using cached https://github.com/p-koo/tfomics/tarball/master\n",
      "Requirement already satisfied: logomaker in /home/koolab/tf_2/lib/python3.6/site-packages (from tfomics==0.1.0.dev0) (0.8)\n",
      "Requirement already satisfied: numpy in /home/koolab/tf_2/lib/python3.6/site-packages (from tfomics==0.1.0.dev0) (1.19.5)\n",
      "Requirement already satisfied: pandas in /home/koolab/tf_2/lib/python3.6/site-packages (from tfomics==0.1.0.dev0) (1.1.5)\n",
      "Requirement already satisfied: scikit-learn in /home/koolab/tf_2/lib/python3.6/site-packages (from tfomics==0.1.0.dev0) (0.24.1)\n",
      "Requirement already satisfied: scipy in /home/koolab/tf_2/lib/python3.6/site-packages (from tfomics==0.1.0.dev0) (1.5.4)\n",
      "Requirement already satisfied: matplotlib in /home/koolab/tf_2/lib/python3.6/site-packages (from logomaker->tfomics==0.1.0.dev0) (3.3.4)\n",
      "Requirement already satisfied: python-dateutil>=2.1 in /home/koolab/tf_2/lib/python3.6/site-packages (from matplotlib->logomaker->tfomics==0.1.0.dev0) (2.8.1)\n",
      "Requirement already satisfied: pillow>=6.2.0 in /home/koolab/tf_2/lib/python3.6/site-packages (from matplotlib->logomaker->tfomics==0.1.0.dev0) (8.1.2)\n",
      "Requirement already satisfied: cycler>=0.10 in /home/koolab/tf_2/lib/python3.6/site-packages (from matplotlib->logomaker->tfomics==0.1.0.dev0) (0.10.0)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /home/koolab/tf_2/lib/python3.6/site-packages (from matplotlib->logomaker->tfomics==0.1.0.dev0) (1.3.1)\n",
      "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.3 in /home/koolab/tf_2/lib/python3.6/site-packages (from matplotlib->logomaker->tfomics==0.1.0.dev0) (2.4.7)\n",
      "Requirement already satisfied: six in /home/koolab/.local/lib/python3.6/site-packages (from cycler>=0.10->matplotlib->logomaker->tfomics==0.1.0.dev0) (1.15.0)\n",
      "Requirement already satisfied: pytz>=2017.2 in /usr/lib/python3/dist-packages (from pandas->tfomics==0.1.0.dev0) (2018.3)\n",
      "Requirement already satisfied: joblib>=0.11 in /home/koolab/tf_2/lib/python3.6/site-packages (from scikit-learn->tfomics==0.1.0.dev0) (1.0.1)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /home/koolab/tf_2/lib/python3.6/site-packages (from scikit-learn->tfomics==0.1.0.dev0) (2.1.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install https://github.com/p-koo/tfomics/tarball/master"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "behind-particle",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "welcome-monaco",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.models import Model\n",
    "\n",
    "import numpy as np\n",
    "import requests as rq\n",
    "import os, io, h5py\n",
    "import pickle as pk\n",
    "\n",
    "from tfomics import moana\n",
    "from tfomics.layers import MultiHeadAttention"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "orange-military",
   "metadata": {},
   "source": [
    "# Retrieve Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "otherwise-eleven",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = rq.get('https://www.dropbox.com/s/c3umbo5y13sqcfp/synthetic_dataset.h5?raw=true')\n",
    "data.raise_for_status()\n",
    "\n",
    "with h5py.File(io.BytesIO(data.content), 'r') as dataset:\n",
    "    x_train = np.array(dataset['X_train']).astype(np.float32).transpose([0, 2, 1])\n",
    "    y_train = np.array(dataset['Y_train']).astype(np.float32)\n",
    "    x_valid = np.array(dataset['X_valid']).astype(np.float32).transpose([0, 2, 1])\n",
    "    y_valid = np.array(dataset['Y_valid']).astype(np.int32)\n",
    "    x_test = np.array(dataset['X_test']).astype(np.float32).transpose([0, 2, 1])\n",
    "    y_test = np.array(dataset['Y_test']).astype(np.int32)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "running-digest",
   "metadata": {},
   "source": [
    "# Define & Train Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "impressive-combat",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['model-016', 'model-016', 'model-032', 'model-064', 'model-128', 'model-256']\n",
      "\n",
      "model-016\n",
      "Train on 21000 samples, validate on 3000 samples\n",
      "Epoch 1/10\n",
      "21000/21000 - 4s - loss: 0.4656 - auroc: 0.5317 - aupr: 0.1626 - val_loss: 0.3974 - val_auroc: 0.6145 - val_aupr: 0.2465\n",
      "Epoch 2/10\n",
      "21000/21000 - 3s - loss: 0.3792 - auroc: 0.6726 - aupr: 0.3547 - val_loss: 0.3416 - val_auroc: 0.7487 - val_aupr: 0.4414\n",
      "Epoch 3/10\n",
      "21000/21000 - 3s - loss: 0.3182 - auroc: 0.7928 - aupr: 0.5378 - val_loss: 0.2667 - val_auroc: 0.8697 - val_aupr: 0.6508\n",
      "Epoch 4/10\n",
      "21000/21000 - 3s - loss: 0.2756 - auroc: 0.8563 - aupr: 0.6480 - val_loss: 0.2554 - val_auroc: 0.8811 - val_aupr: 0.6865\n",
      "Epoch 5/10\n",
      "21000/21000 - 3s - loss: 0.2556 - auroc: 0.8821 - aupr: 0.6947 - val_loss: 0.2582 - val_auroc: 0.8809 - val_aupr: 0.6933\n",
      "Epoch 6/10\n",
      "21000/21000 - 3s - loss: 0.2401 - auroc: 0.8993 - aupr: 0.7290 - val_loss: 0.2183 - val_auroc: 0.9205 - val_aupr: 0.7614\n",
      "Epoch 7/10\n",
      "21000/21000 - 3s - loss: 0.2340 - auroc: 0.9046 - aupr: 0.7420 - val_loss: 0.2202 - val_auroc: 0.9223 - val_aupr: 0.7742\n",
      "Epoch 8/10\n",
      "21000/21000 - 3s - loss: 0.2305 - auroc: 0.9077 - aupr: 0.7489 - val_loss: 0.2140 - val_auroc: 0.9262 - val_aupr: 0.7782\n",
      "Epoch 9/10\n",
      "21000/21000 - 3s - loss: 0.2274 - auroc: 0.9100 - aupr: 0.7559 - val_loss: 0.1991 - val_auroc: 0.9377 - val_aupr: 0.7977\n",
      "Epoch 10/10\n",
      "21000/21000 - 3s - loss: 0.2249 - auroc: 0.9126 - aupr: 0.7602 - val_loss: 0.2195 - val_auroc: 0.9319 - val_aupr: 0.7928\n"
     ]
    }
   ],
   "source": [
    "category = \"filters\"\n",
    "variants = [1, 16, 32, 64, 128, 256]\n",
    "\n",
    "places = len(str(max(variants)))\n",
    "names = [f\"model-{str(variants[i]).zfill(places)}\" for i in range(len(variants))]\n",
    "print(names)\n",
    "\n",
    "if not os.path.exists(f'models/{category}'):\n",
    "    os.makedirs(f'models/{category}')\n",
    "if not os.path.exists(f'motifs/{category}'):\n",
    "    os.makedirs(f'motifs/{category}')\n",
    "\n",
    "for i in range(len(variants)):\n",
    "    # Input\n",
    "    inputs = layers.Input(shape=(200, 4))\n",
    "\n",
    "    # Convolutional Block\n",
    "    nn = layers.Conv1D(filters=variants[i], kernel_size=19, use_bias=False, padding='same')(inputs)\n",
    "    nn = layers.Activation('relu', name='conv_activation')(nn)\n",
    "    nn = layers.MaxPool1D(pool_size=25)(nn)\n",
    "    nn = layers.Dropout(0.1)(nn)\n",
    "\n",
    "    # Positional Encoding\n",
    "    positions = tf.range(nn.shape[1])\n",
    "    context = layers.Embedding(input_dim=nn.shape[1], output_dim=nn.shape[2])(positions)\n",
    "    nn = tf.add(nn, context)\n",
    "\n",
    "    # Multi-Head Attention\n",
    "    nn, weights = MultiHeadAttention(num_heads=16, d_model=64)(nn, nn, nn)\n",
    "    nn = layers.Dropout(0.1)(nn)\n",
    "\n",
    "    nn = layers.Flatten()(nn)\n",
    "\n",
    "    # Feed Forward\n",
    "    nn = layers.Dense(512, use_bias=False)(nn)\n",
    "    nn = layers.BatchNormalization()(nn)\n",
    "    nn = layers.Activation('relu')(nn)\n",
    "    nn = layers.Dropout(0.5)(nn)\n",
    "\n",
    "    # Output\n",
    "    outputs = layers.Dense(12, activation='sigmoid')(nn)\n",
    "\n",
    "    # Compile model\n",
    "    model = Model(inputs=inputs, outputs=outputs, name=names[i])\n",
    "    print('\\n' + model.name)\n",
    "\n",
    "    auroc = tf.keras.metrics.AUC(curve='ROC', name='auroc')\n",
    "    aupr = tf.keras.metrics.AUC(curve='PR', name='aupr')\n",
    "    model.compile(tf.keras.optimizers.Adam(0.0005), loss='binary_crossentropy', metrics=[auroc, aupr])\n",
    "    \n",
    "    # Train Model\n",
    "    lr_decay = tf.keras.callbacks.ReduceLROnPlateau(monitor='val_aupr', factor=0.2, patient=5, verbose=1, min_lr=1e-7, mode='max')\n",
    "    model.fit(x_train, y_train, epochs=10, validation_data=(x_valid, y_valid), callbacks=[lr_decay], verbose=2, shuffle=True)\n",
    "    \n",
    "    # Save Model\n",
    "    save_path = os.path.join('models', category, names[i] + '.h5')\n",
    "    model.save_weights(save_path)\n",
    "    \n",
    "    #Extract PPMs\n",
    "    index = [type(j) for j in model.layers].index(tf.keras.layers.Activation)\n",
    "    \n",
    "    ppms = moana.filter_activations(x_test, model, layer=index, window=20, threshold=0.5)\n",
    "    ppms = moana.clip_filters(ppms, threshold=0.5, pad=3)\n",
    "    \n",
    "    moana.meme_generate(ppms, output_file=f'motifs/{category}/{names[i]}.txt', prefix='filter')\n",
    "    \n",
    "    break\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
